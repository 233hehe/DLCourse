{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = dsets.MNIST(root = \"./data\",\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dsets.MNIST(root = \"./data\",\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* totaldata:60000\n",
    "* minibatch:100\n",
    "    iterations:3000\n",
    "       1 iteration: one mini-batch f/b pass\n",
    "* epochs\n",
    "    1 epoch: running through whole dataset\n",
    "       epochs = iterations/ (totaldata/minibatch) = 3000 / 600 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "totaldata = len(train_dataset)\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = int(n_iters/(totaldata/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset= train_dataset,\n",
    "                                          batch_size= batch_size,\n",
    "                                          shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset= test_dataset,\n",
    "                                          batch_size= batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "input_dim = 28* 28\n",
    "output_dim = 10\n",
    "model = LogisticRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion  = nn.CrossEntropyLoss()\n",
    "eta = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0067,  0.0197, -0.0163,  ..., -0.0215, -0.0014, -0.0150],\n",
      "        [-0.0140,  0.0160,  0.0049,  ..., -0.0150, -0.0188,  0.0011],\n",
      "        [-0.0220, -0.0129,  0.0350,  ...,  0.0338,  0.0030,  0.0311],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0057, -0.0320,  ...,  0.0124, -0.0008, -0.0200],\n",
      "        [ 0.0142,  0.0310,  0.0294,  ..., -0.0254, -0.0025,  0.0236],\n",
      "        [-0.0033, -0.0192, -0.0080,  ..., -0.0170,  0.0130,  0.0155]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 2.1990e-02,  3.1188e-02, -2.5442e-03, -4.0659e-03, -6.0600e-03,\n",
      "        -4.2688e-05,  3.0836e-02,  8.1216e-03,  2.9412e-03,  3.4640e-02],\n",
      "       requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 500, loss 1.600559949874878, accuracy 75\n",
      "iter 1000, loss 1.3492779731750488, accuracy 78\n",
      "iter 1500, loss 1.2272416353225708, accuracy 80\n",
      "iter 2000, loss 1.113019585609436, accuracy 81\n",
      "iter 2500, loss 0.9918678998947144, accuracy 82\n",
      "iter 3000, loss 0.9861036539077759, accuracy 83\n"
     ]
    }
   ],
   "source": [
    "iter = 0 \n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # kload images as variable\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward \n",
    "        outpus = model(images)\n",
    "        \n",
    "        # calcualte loss\n",
    "        loss = criterion(outpus, labels)\n",
    "        \n",
    "        # backward gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # updateing parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total =0 \n",
    "            for images, labels in test_loader:\n",
    "                 # kload images as variable\n",
    "                images = Variable(images.view(-1, 28*28))\n",
    "        \n",
    "                # forward \n",
    "                outputs = model(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # backward gradients\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # updateing parameters\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            print(f\"iter {iter}, loss {loss}, accuracy {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
